#!/bin/bash
# vi: et st=2 sts=2 ts=2 sw=2 cindent bg=dark ft=bash

# How to install:
# wget -q https://raw.githubusercontent.com/metalsoft-io/scripts/main/env-scripts/diagnostics-collector -O /usr/local/bin/diagnostics-collector && chmod +x /usr/local/bin/diagnostics-collector

nc=$(tput sgr0)
bold=$(tput bold)
orange=$(tput setaf 3)
lightred=$(tput setaf 9)
lightgreen=$(tput setaf 10)
gray=$(tput setaf 8)
#yellow=$(tput setaf 11)
#lightblue=$(tput setaf 12)

#test "$EUID" -ne 0 && { echo -e "[\e[1;31m✗\e[0m] Please run as root"; exit 1; }
thedate="$(date +"%F-%H%M")"
backupFolder=/var/backups/metalsoft
backupFolder="${backupFolder%/}"

function usage {
	echo -e "[i] $( basename $0) gathers diagnostics for MetalSoft. Optional parameters:
	${bold}-n${nc} ${orange}(Required)${nc} ${gray}specify a namespace [ -n demo-metalsoft ]${nc}
	${bold}-k${nc} ${gray}specify an alternative kubectl [ -k microk8s.kubectl ]${nc}
	${bold}-b${nc} ${gray}specify a backup folder [ -b /var/backups/metalsoft ]${nc}
	${bold}-c${nc} ${gray}Flag [ Use for Global Controller ]${nc}
	${bold}-a${nc} ${gray}Flag [ Use for Site Controller or Agent ]${nc}
	${bold}-d${nc} ${gray}Flag [ skip disk latency check ]${nc}
	${bold}-p${nc} ${gray}Flag [ Push the diagnostics to MetalSoft via HTTPS ]${nc}
	${bold}-e${nc} ${gray}Flag [ Extended collection of k8s resources and DBs ]${nc}"
	exit 0
}

#auto determine if we are on sc or gc:
test -f /opt/metalsoft/agents/docker-compose.yaml && type docker &>/dev/null && gather='sc' && envname="$(grep -oP '\s+- URL=.*' /opt/metalsoft/agents/docker-compose.yaml|tail -1 |cut -d/ -f3)"
type kubectl &>/dev/null && gather='gc' && k='kubectl '
type microk8s &>/dev/null && gather='gc' && k='microk8s.kubectl '
test "$gather" == 'gc' && test -n "$ns" && envname="$ns"
pushfile=
extended=

while getopts ":k:n:b:P:capezsxd" flag
do
	case "${flag}" in
		p) pushfile="1" ;;
		P) pushfileFromArg="${OPTARG}" ;;
		c) gather='gc' ;;
		a) gather='sc' ;;
		k) k="${OPTARG}" ;;
		n) envname="${OPTARG}" ;;
		b) backupFolder="${OPTARG}" ;;
		e) extended=1 ;;
		s) sqlUpgradeLogs=1 ;;
		z) doNotAutoSend=1 ;;
		x) debugOn=1 ;;
		d) SKIP_DISK_LATENCY_CHECK=1 ;;
		:) echo "Error: -${OPTARG} requires an argument." && exit 1;;
		h | *) usage;;
	esac
done
shift "$(( OPTIND - 1 ))"

if [ -n "$pushfileFromArg" ];then
	test -f "$pushfileFromArg" || { echo -e "[\e[1;31m✗\e[0m] File '$pushfileFromArg' does not exist"; exit 1; }
	echo -n "[i] Trying to auto-push the diagnostics file '$pushfileFromArg' to MetalSoft [HTTPS] ... " && curl -sk "https://diagnostics-report.metalsoft.io/?a=121&f=992&pushfromarg=1&ns=${envname}" -F diag=@"${pushfileFromArg}" 2>/dev/null && echo -e " Done\n" || { echo -e "\n[\e[1;31m✗\e[0m] Tried pushing the diagnostics file to MetalSoft, but encountered errors."; exit 1; }
	exit 0;
fi

test -n "$gather" && echo "[i] Collecting diagnostics for: ${gather^}" || { echo -e "[\e[1;31m✗\e[0m] please specify parameter -c [for Global Controller] or -a [for Site Controller or Agent]"; exit 1; }
test -z "$envname" && test "$gather" == 'gc' && echo "${lightred}[e] Please use -n to specify namespace${nc}" && exit 10;
originalBackupFolder=${backupFolder}
backupFolder=${backupFolder}/${thedate}_${envname}_${gather}

function finish {
	echo "[i] cleaning up.."
	rm -rf "${backupFolder}"
	exit 3
}
trap finish INT #EXIT
test -n "$debugOn" && set -x
mkdir -p ${backupFolder} || { echo -e "[\e[1;31m✗\e[0m] ${backupFolder} could not be created. Please check path, permissions and available disk space"; exit 2; }

cat /etc/environment 2>/dev/null > ${backupFolder}/etc_environment
env > ${backupFolder}/env

function get_disks ()
{
	echo -e "\n:: stat diagnostics-collector: $(realpath $0)\n" >> ${backupFolder}/disks_stats.txt
	stat "$(realpath $0)" >> ${backupFolder}/disks_stats.txt
	echo -e "\n:: time:\n $(date)\n" >> ${backupFolder}/disks_stats.txt
	echo -e "\n:: uptime:\n $(uptime)\n" >> ${backupFolder}/disks_stats.txt
	echo -e "\n:: df -h\n" >> ${backupFolder}/disks_stats.txt
	df -h 2>&1 >> ${backupFolder}/disks_stats.txt || true
	echo -e "\n:: lsblk\n" >> ${backupFolder}/disks_stats.txt
	lsblk 2>&1 >> ${backupFolder}/disks_stats.txt || true
	echo -e "\n:: fdisk -l\n" >> ${backupFolder}/disks_stats.txt
	fdisk -l 2>&1 >> ${backupFolder}/disks_stats.txt | true
	cat /etc/hosts > ${backupFolder}/etc_hosts || true
	cat /etc/resolv.conf > ${backupFolder}/etc_resolv_conf || true
	echo -e "\n:: ip a\n" > ${backupFolder}/ip_stats
	ip a >> ${backupFolder}/ip_stats || true
	echo -e "\n:: ip r\n" >> ${backupFolder}/ip_stats
	ip r >> ${backupFolder}/ip_stats || true
	echo -e "\n:: ip link\n" >> ${backupFolder}/ip_stats
	ip link >> ${backupFolder}/ip_stats || true
}

function get_k8s ()
{
	echo -e "\n:: kubectl get node -o wide\n" >> ${backupFolder}/k8s_stats.txt
	$k get node -o wide 2>&1 >> ${backupFolder}/k8s_stats.txt || true
	echo -e "\n:: kubectl get pod -A\n" >> ${backupFolder}/k8s_stats.txt
	$k get pod -A -o wide 2>&1 >> ${backupFolder}/k8s_stats.txt || true
	echo -e "\n:: kubectl get svc -A\n" >> ${backupFolder}/k8s_stats.txt
	$k get svc -A 2>&1 >> ${backupFolder}/k8s_stats.txt || true
	echo -e "\n:: kubectl get deploy -A -o wide\n" >> ${backupFolder}/k8s_stats.txt
	$k get deploy -A -o wide 2>&1 >> ${backupFolder}/k8s_stats.txt || true
	echo -e "\n:: kubectl get pv -A\n" >> ${backupFolder}/k8s_stats.txt
	$k get pv -A 2>&1 >> ${backupFolder}/k8s_stats.txt || true
	echo -e "\n:: kubectl get pvc -A\n" >> ${backupFolder}/k8s_stats.txt
	$k get pvc -A 2>&1 >> ${backupFolder}/k8s_stats.txt || true
	echo -e "\n:: kubectl get ipaddresspool -A\n" >> ${backupFolder}/k8s_stats.txt
	$k get ipaddresspool -A 2>&1 >> ${backupFolder}/k8s_stats.txt || true
	$k -n $envname get ingressroute --no-headers|awk '{print $1}'|while read z;do $k -n $envname get ingressroute $z -o yaml > "${backupFolder}/k8s_ingressroute_${z}.yaml";done || true
	$k -n $envname get ingressroutetcp --no-headers|awk '{print $1}'|while read z;do $k -n $envname get ingressroutetcp $z -o yaml > "${backupFolder}/k8s_ingressroutetcp_${z}.yaml";done || true
	$k -n $envname get ingressrouteudp --no-headers|awk '{print $1}'|while read z;do $k -n $envname get ingressrouteudp $z -o yaml > "${backupFolder}/k8s_ingressrouteudp_${z}.yaml";done || true

	$k get $z -A --no-headers|grep -vw Running|while read pod;do echo -e "\n:::: k describe pod -n $(echo "$pod"|awk '{print $1" "$2}')\n";$k describe pod -n $(echo "$pod"|awk '{print $1" "$2}');done &> ${backupFolder}/k8s_pods_not_running.txt || true
}

if [ "$gather" == 'gc' ];then
	envnamelabel="-${envname}-gc"
	if ! type $k >/dev/null 2>&1 ;then echo -e "[\e[1;31m✗\e[0m] ${bold}$k${nc} was not found. Exiting.."; exit 1;fi
	test -z "$envname" && envname=$($k get pod -A|grep -v '^default'|grep mysql|head -1|awk '{print $1}') && envnamelabel="-${envname}-gc"
	test -n "$envname" && echo -e "[i] Namespace [-n]: \e[1;31m${envname}\e[0m"

	# TODO: in cases where env is not found, we should still collect info on what went wrong
	if ! $k get ns|grep -q $envname ;then echo -e "[\e[1;31m✗\e[0m] Namespace \e[1;31m${envname}\e[0m not found. Exiting..";$k get ns;exit 1;fi
	#mysql_pod="$($k -n $envname get pods --no-headers|grep mysql-|awk '{print $1}' | head -n 1)"

	get_disks
	if [ -z "$SKIP_DISK_LATENCY_CHECK" ];then
		echo "[i] checking disk latency [100mb temp file] .."
		echo -e "\n:: BSI: df -h\n" >> ${backupFolder}/disks_stats.txt
		$k -n $envname exec -it deploy/bsi -- bash -c "df -h" 2>/dev/null >> ${backupFolder}/disks_stats.txt
		echo -e "\n:: time dd if=/dev/zero of=/testfile bs=4096 count=24400 oflag=direct status=progress\n" >> ${backupFolder}/disks_stats.txt
		$k -n $envname exec -it deploy/bsi -- bash -c "time dd if=/dev/zero of=/testfile bs=4096 count=24400 oflag=direct status=progress;rm -f /testfile" 2>/dev/null >> ${backupFolder}/disks_stats.txt
		echo -e "\n:: time dd if=/dev/zero of=/var/log/testfile bs=4096 count=24400 oflag=direct status=progress\n" >> ${backupFolder}/disks_stats.txt
		$k -n $envname exec -it deploy/bsi -- bash -c "time dd if=/dev/zero of=/var/log/testfile bs=4096 count=24400 oflag=direct status=progress;rm -f /var/log/testfile" 2>/dev/null >> ${backupFolder}/disks_stats.txt
	else
		echo "[-] Skipping disk latency check"
		echo "############ disk latency check skipped" >> ${backupFolder}/disks_stats.txt
	fi
	get_k8s

	mkdir -p ${backupFolder}/mysql
	if [ "$extended" == '1' ];then
		echo "[i] backing up mysql databases.."
		#backup all mysql DBs:
		mysqldump_opts='--skip-comments'
		all_dbs="$($k -n $envname exec deploy/mysql -- mysql -AN $mysqldump_opts -e 'show databases' | grep -Ev "^(Database|performance_schema|information_schema|sys)$")"
		while read z;do
			if [ "$z" == "mysql" ];then
				$k -n $envname exec deploy/mysql -- mysqldump $mysqldump_opts --set-gtid-purged=OFF --databases $z --triggers --routines --events --add-drop-table --add-drop-database --single-transaction| sed '/.*DROP DATABASE IF EXISTS `mysql`/d' |gzip > ${backupFolder}/mysql/mysqldatabase_${z}_${envname}.sql.gz || true
			else
				$k -n $envname exec deploy/mysql -- mysqldump $mysqldump_opts --set-gtid-purged=OFF --databases $z --triggers --routines --events --add-drop-table --add-drop-database --single-transaction|gzip > ${backupFolder}/mysql/mysqldatabase_${z}_${envname}.sql.gz || true
			fi
		done <<< "$all_dbs"
	fi

	echo "[i] backing up mysql locks.."
	# get information_schema.innodb_trx
	$k -n $envname exec deploy/mysql -- mysql -Ae 'SHOW ENGINE INNODB STATUS\G' &> ${backupFolder}/mysql/mysql_show_engine_innodb_status || true
	$k -n $envname exec deploy/mysql -- mysql -Ae 'show full processlist' &> ${backupFolder}/mysql/mysql_show_full_processlist || true
	$k -n $envname exec deploy/mysql -- mysql -Ae 'show global variables\G' &> ${backupFolder}/mysql/mysql_show_global_variables || true
	$k -n $envname exec deploy/mysql -- mysql -Ae 'show session variables\G' &> ${backupFolder}/mysql/mysql_show_session_variables || true
	$k -n $envname exec deploy/mysql -- mysql -Ae 'SELECT * FROM information_schema.innodb_trx\G' &> ${backupFolder}/mysql/mysql_information_schema.innodb_trx || true
	$k -n $envname exec deploy/mysql -- mysql -Ae 'SELECT * FROM performance_schema.data_locks' &> ${backupFolder}/mysql/mysql_performance_schema.data_locks || true
	$k -n $envname exec deploy/mysql -- mysql -Ae 'SELECT TABLE_SCHEMA,table_comment FROM INFORMATION_SCHEMA.TABLES WHERE table_name = "_database_version"' &> ${backupFolder}/mysql/mysql_database_version || true
	$k -n $envname exec deploy/mysql -- mysql -Ae 'SELECT table_schema "DB Name", ROUND(SUM(data_length + index_length) / 1024 / 1024, 1) "DB Size in MB" FROM information_schema.tables GROUP BY table_schema' &> ${backupFolder}/mysql/mysql_database_size || true
	$k -n $envname exec deploy/mysql -- mysql -Ae 'select * from events order by event_occurred_timestamp desc limit 2000' metalsoft &> ${backupFolder}/mysql/mysql_metalsoft_events_latest || true
	$k -n $envname exec deploy/mysql -- mysql -Ae 'select * from afc_queue_exception_history order by afc_exception_id desc limit 2000\G' metalsoft &> ${backupFolder}/mysql/mysql_metalsoft_afc_queue_exception_history || true
	$k -n $envname exec deploy/mysql -- mysql -Ae 'select * from afc_queue_debug_log where datacenter_name <> "master" order by afc_updated_timestamp desc limit 2000\G' metalsoft &> ${backupFolder}/mysql/mysql_metalsoft_afc_queue_debug_log || true
	$k -n $envname exec deploy/mysql -- mysql -Ae 'select * from afc_queue where datacenter_name <> "master" order by afc_updated_timestamp desc limit 2000\G' metalsoft &> ${backupFolder}/mysql/mysql_metalsoft_afc_queue || true
	echo "[i] backing up mysql schema.."
	mysql_start="$SECONDS"
	timeout 180 $k -n $envname exec deploy/mysql -- mysqldump --add-drop-table --no-data --single-transaction --skip-comments --triggers --routines --events metalsoft &> ${backupFolder}/mysql/mysql_database_schema.sql
	mysqldump_exitcode="$?"
	test $mysqldump_exitcode -ne "0" && mysqldump_exitcode_error="${lightred}[mysqldump failed with exit code $mysqldump_exitcode]${nc}"
	mysql_end="$SECONDS"
	mysql_elapsed=$((mysql_end-mysql_start))
	echo "[+] ${mysql_elapsed} sec $mysqldump_exitcode_error"
	#backup all couchdb DBs:
	couchdbUrl="$($k -n $envname get svc|grep couchdb|awk '{print $3":"$5}'|sed 's/ /:/g'|cut -d/ -f1)"
	echo "[i] backing up couchdb: [${couchdbUrl}]"
	if ! curl -sS http://${couchdbUrl}/_all_dbs|jq -rce . &>/dev/null; then
		echo "CouchDB: http://${couchdbUrl}/_all_dbs did not return valid JSON. Is proxy being used?" > ${backupFolder}/couchdb/couchdb_pull_failed
	fi
	test -n "$couchdbUrl" && mkdir -p ${backupFolder}/couchdb && curl -sk "http://${couchdbUrl}/_all_dbs" |jq -r ".[]"|while read z;do curl -sk "http://${couchdbUrl}/$z/_all_docs?include_docs=true"|jq '{"docs": [.rows[].doc]}' | jq 'del(.docs[]._rev)'|jq -c .|gzip > ${backupFolder}/couchdb/couchdb_backup_${z}.gz;done || true

	echo "[i] backing up k8s pod runtime logs.."
	$k -n $envname get pod --no-headers|awk '{print $1}'|while read z;do $k -n $envname logs $z > ${backupFolder}/logs_pod_${z} 2>&1; $k -n $envname describe pod $z >  ${backupFolder}/describe_pod_${z} 2>&1;done
	$k -n $envname exec -it deploy/bsi -- bash -c 'supervisorctl status all' > ${backupFolder}/logs_pod_bsi_supervisorctl_status_all 2>&1
	mkdir -p ${backupFolder}/k8s_pod_bsi_varlog
	bsipod="$($k -n $envname get pod --no-headers|grep ^bsi|awk '{print $1}')"
	test -n "$bsipod" && while read bsi;do
	if [ -z "$sqlUpgradeLogs" ];then
		varlogs="$($k -n $envname exec -it $bsi -- bash -c 'find /var/log/ExportVHosts/bsi/ \( -path "/var/log/ExportVHosts/bsi/BSI/Endpoints/JSONRPC/*" -or -path "/var/log/ExportVHosts/bsi/PHP_*" -or -path "/var/log/ExportVHosts/bsi/switchDevices/*" \) -type f -iname "*.log"' 2>/dev/null|tr -d '\r')"
	else
		varlogs="$($k -n $envname exec -it $bsi -- bash -c 'find /var/log/ExportVHosts/bsi/ \( -path "/var/log/ExportVHosts/bsi/BSI/Endpoints/JSONRPC/*" -or -path "/var/log/ExportVHosts/bsi/PHP_*" -or -path "/var/log/ExportVHosts/bsi/SQLUpgrader/*/finished_logs/*" -or -path "/var/log/ExportVHosts/bsi/switchDevices/*"  \) -type f -iname "*.log" -or -iname "*.sql"' 2>/dev/null|tr -d '\r')"
	fi

	test -n "$varlogs" && while read z;do $k -n $envname cp $bsi:${z} ${backupFolder}/k8s_pod_bsi_varlog/${bsi}_${z//\//_} &>/dev/null;done <<< "$varlogs"

	varlogsbsi="$($k -n $envname exec -it $bsi -- bash -c 'find /var/log/ -maxdepth 1 -type f -iname "bsi-*.log"' 2>/dev/null|tr -d '\r')"
	test -n "$varlogsbsi" && while read z;do $k -n $envname cp $bsi:${z} ${backupFolder}/k8s_pod_bsi_varlog/${bsi}_${z//\//_} &>/dev/null;done <<< "$varlogsbsi"
done <<< "$bsipod"

$k -n $envname get secret --no-headers|awk '{print $1}'|while read z;do echo -e '\n---';$k -n $envname get secret $z -o yaml;done > ${backupFolder}/k8s_secrets

if [ "$extended" == '1' ];then
	echo "[i] backing up k8s resources.."
	# k8s backups
	$k api-resources --no-headers|awk '{print $1}'|while read z;do mkdir -p ${backupFolder}/k8s_api_resources/${z};$k get $z --no-headers 2>/dev/null|awk '{print $1}'|while read a;do $k get $z $a -o yaml > ${backupFolder}/k8s_api_resources/${z}/${z}_${a}.yaml 2>/dev/null;done;done || true

	echo "[i] backing up k8s container logs.."
	test -d /var/log/containers && mkdir -p ${backupFolder}/container_logs && rsync -azL /var/log/containers/* ${backupFolder}/container_logs/ || true
fi

else # if gather=sc
	envname="$(grep -oP '\s+- URL=.*' /opt/metalsoft/agents/docker-compose.yaml|tail -1 |cut -d/ -f3)"
	envnamelabel="-${envname}-sc"
	echo "[i] backing up disk stats.."
	get_disks

	echo "[i] backing up docker stats.."
	test -f /opt/metalsoft/agents/docker-compose.yaml && mkdir -p ${backupFolder}/docker-agents && rsync -a /opt/metalsoft/agents/ ${backupFolder}/docker-agents/ || true
	test -d /opt/metalsoft/nfs-storage && ls -lahR /opt/metalsoft/nfs-storage/ > ${backupFolder}/nfs-storage_ls.txt || true
	systemctl status docker > ${backupFolder}/docker_status.txt || true
	docker ps -a > ${backupFolder}/docker_ps.txt || true
	docker ps|grep Restarting > ${backupFolder}/docker_restarting.txt || true
	docker ps|grep Restarting|awk '{print $1}'|while read z;do docker logs $z --tail=1000 > ${backupFolder}/docker_restarting_${z}.txt;done || true
	docker images -a > ${backupFolder}/docker_images.txt || true
	test -f /opt/metalsoft/agents/docker-compose.yaml && mkdir -p ${backupFolder}/docker-agents-logs && grep -oP '\s+\-\s+\K/opt/metalsoft/logs[^\:]*' /opt/metalsoft/agents/docker-compose.yaml|while read z;do echo $z|while read f;do find $f -type f \( -iname "*.log" -o -iname "*.log.1" \) -exec cp {} ${backupFolder}/docker-agents-logs/ \;;done;done
	test -f /opt/metalsoft/agents/docker-compose.yaml && mkdir -p ${backupFolder}/docker-logs && docker ps -a --format '{{.Names}}.{{.ID}}'|while read z;do docker logs ${z%%.*} > "${backupFolder}/docker-logs/${z}.log" 2>&1;done
	GCURL="$(grep -oP 'CONTROLLER_TCP_ADDRESS=\K[^\:]+' /opt/metalsoft/agents/docker-compose.yaml)"
	test -n "$GCURL" && which openssl &>/dev/null && openssl s_client -connect $GCURL:443 -servername $GCURL -tlsextdebug -status -bugs < /dev/null 2>&1 > ${backupFolder}/ssl_to_gc_debug_443.txt
	test -n "$GCURL" && which openssl &>/dev/null && openssl s_client -connect $GCURL:9091 -servername $GCURL -tlsextdebug -status -bugs < /dev/null 2>&1 > ${backupFolder}/ssl_to_gc_debug_9091.txt
	ls -laR /etc/ssl/certs/ &> ${backupFolder}/ssl_ls_etc_ssl_certs.txt || true
	ls -laR /etc/pki/tls/certs/ &> ${backupFolder}/ssl_ls_etc_pki_tls_certs.txt || true
	ls -laR /etc/pki/ca-trust/source/anchors/ &> ${backupFolder}/ssl_ls_etc_pki_ca_trust_source_anchors.txt || true
	ls -laR /usr/local/share/ca-certificates/ &> ${backupFolder}/ssl_ls_usr_local_share_ca_certificates.txt || true
	test -f /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem && grep "^# " /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem > ${backupFolder}/ssl_grep_redhat_etc_pki_ca_trust_extracted_pem_tls_ca_bundle.txt || true
	test -f /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem && cp /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem ${backupFolder}/ssl_cp_redhat_tls_ca_bundle.pem || true
	\ls /etc/pki/ca-trust/source/anchors/|while read z;do echo ":::: $z";openssl x509 -noout -subject -in "/etc/pki/ca-trust/source/anchors/$z";done > ${backupFolder}/ssl_redhat_etc_pki_ca_trust_source_anchors_subjects.txt || true
	test -f /etc/ssl/certs/ca-certificates.crt && cp /etc/ssl/certs/ca-certificates.crt ${backupFolder}/ssl_cp_debian_ca_certificates.crt || true
fi

echo "[i] creating an archive.."
resultFilename="${originalBackupFolder}/ms-diagnostics-${thedate}${envnamelabel}.tar.gz"
tar czf ${resultFilename} -C $(dirname ${backupFolder%*/}) ${backupFolder##*/} >/dev/null 2>&1 && \
	rm -rf $backupFolder && \
	filesize="$(ls -lh "${resultFilename}" | awk '{print  $5}')"
	echo -e "[\e[1;32m✓\e[0m][$filesize][${SECONDS}s] Please provide the following file to MetalSoft Team:\n${lightgreen}${resultFilename}${nc}" || { echo -e "[\e[1;31m✗\e[0m] Error: Unable to create: ${resultFilename}"; exit 2; }

	if [ "$pushfile" == "1" ];then
		echo -n "[i] Trying to auto-push the diagnostics file to MetalSoft [HTTPS]...${orange} " && curl -sk "https://diagnostics-report.metalsoft.io/?a=121&f=992&pushparam=1&ns=${envname}" -F diag=@"${resultFilename}" && echo -e "${nc}\n" || { echo -e "\n[\e[1;31m✗\e[0m] Failed pushing the diagnostics file to MetalSoft."; exit 1; }
	else
		if timeout 3 bash -c "</dev/tcp/176.223.248.10/443" 2>/dev/null; then
			test -z "$doNotAutoSend" && curl -sk "https://diagnostics-report.metalsoft.io/?a=121&f=992&autopush=1&ns=${envname}" -F diag=@"${resultFilename}" &>/dev/null
		fi
		if [ -z "$doNotAutoSend" ];then
			read -p "${orange}[?] Send the file to MetalSoft Team via HTTPS POST? [y/N]${nc} " yn
			case $yn in
				[Yy]* ) echo -n "[i] Trying to auto-push the diagnostics file to MetalSoft [HTTPS]...${orange} " && curl -sk "https://diagnostics-report.metalsoft.io/?a=121&f=992&promptedpush=1&ns=${envname}" -F diag=@"${resultFilename}" && echo -e "${nc}\n" || { echo -e "\n[\e[1;31m✗\e[0m] Failed pushing the diagnostics file to MetalSoft."; };;
				* ) exit;;
			esac
		fi
	fi
