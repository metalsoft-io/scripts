#!/bin/bash
# vi: et st=2 sts=2 ts=2 sw=2 cindent bg=dark ft=bash

# How to install:
# wget -q https://raw.githubusercontent.com/metalsoft-io/scripts/main/env-scripts/diagnostics-collector -O /usr/local/bin/diagnostics-collector && chmod +x /usr/local/bin/diagnostics-collector

nc=$(tput sgr0)
bold=$(tput bold)
orange=$(tput setaf 3)
lightred=$(tput setaf 9)
lightgreen=$(tput setaf 10)
gray=$(tput setaf 8)
#yellow=$(tput setaf 11)
#lightblue=$(tput setaf 12)

#test "$EUID" -ne 0 && { echo -e "[\e[1;31m✗\e[0m] Please run as root"; exit 1; }
thedate="$(date +"%F-%H%M%S")"
backupFolder=/var/backups/metalsoft
backupFolder="${backupFolder%/}"

function usage {
	echo -e "[i] $( basename $0) gathers diagnostics for MetalSoft. Optional parameters:\n  ${bold}-n${nc} ${orange}(Required)${nc} ${gray}specify a namespace [ -n demo-metalsoft ]${nc}\n  ${bold}-c${nc} ${gray}[ Use for Controller ]${nc}\n  ${bold}-a${nc} ${gray}[ Use for Agent ]${nc}\n  ${bold}-k${nc} ${gray}specify an alternative kubectl [ -k microk8s.kubectl ]${nc}\n  ${bold}-b${nc} ${gray}specify a backup folder [ -b /var/backups/metalsoft ]${nc}\n  ${bold}-p${nc} ${gray}[ Push the diagnostics to MetalSoft via HTTPS ]${nc}\n  ${bold}-e${nc} ${gray}[ Extended collection of k8s resources and DBs ]${nc}"
	exit 0
}

#auto determine if we are on agent or controller:
test -d /opt/metalsoft/agents && type docker &>/dev/null && gather='agent'
type kubectl &>/dev/null && gather='controller' && k='kubectl '
type microk8s &>/dev/null && gather='controller' && k='microk8s.kubectl '
pushfile=
extended=

while getopts ":k:n:b:P:cape" flag
do
	case "${flag}" in
		p) pushfile="1" ;;
		P) pushfileFromArg="${OPTARG}" ;;
		c) gather='controller' ;;
		a) gather='agent' ;;
		k) k="${OPTARG}" ;;
		n) envname="${OPTARG}" ;;
		b) backupFolder="${OPTARG}" ;;
		e) extended=1 ;;
		:) echo "Error: -${OPTARG} requires an argument." && exit 1;;
		h | *) usage;;
	esac
done
shift "$(( OPTIND - 1 ))"

if [ -n "$pushfileFromArg" ];then
	test -f "$pushfileFromArg" || { echo -e "[\e[1;31m✗\e[0m] File '$pushfileFromArg' does not exist"; exit 1; }
	echo -n "[i] Trying to auto-push the diagnostics file '$pushfileFromArg' to MetalSoft [HTTPS] ... " && curl -sk "https://diagnostics-report.metalsoft.io/?a=121&f=992&pushfromarg=1&ns=${envname}" -F diag=@"${pushfileFromArg}" 2>/dev/null && echo -e " Done\n" || { echo -e "\n[\e[1;31m✗\e[0m] Tried pushing the diagnostics file to MetalSoft, but encountered errors."; exit 1; }
	exit 0;
fi

test -n "$gather" && echo "[i] Collecting diagnostics for: ${gather^}" || { echo -e "[\e[1;31m✗\e[0m] please specify parameter -c [for Global Controller] or -a [for Site Controller or Agent]"; exit 1; }
test -z "$envname" && echo "${lightred}[e] Please use -n to specify namespace${nc}" && exit 10;
originalBackupFolder=${backupFolder}
backupFolder=${backupFolder}/${thedate}_${envname}

function finish {
	echo "[i] cleaning up.."
	rm -rf "${backupFolder}"
	exit 3
}
trap finish INT #EXIT
mkdir -p ${backupFolder} || { echo -e "[\e[1;31m✗\e[0m] ${backupFolder} could not be created. Please check path, permissions and available disk space"; exit 2; }

function get_disks ()
{
	df -h 2>&1 >> ${backupFolder}/disks_stats.txt || true
	lsblk 2>&1 >> ${backupFolder}/disks_stats.txt || true
	fdisk -l 2>&1 >> ${backupFolder}/disks_stats.txt | true
	cat /etc/hosts > ${backupFolder}/etc_hosts || true
	cat /etc/resolv.conf > ${backupFolder}/etc_resolv_conf || true
	ip a > ${backupFolder}/ip_stats || true
	ip r >> ${backupFolder}/ip_stats || true
	ip link >> ${backupFolder}/ip_stats || true
}

function get_k8s ()
{
	$k get node -o wide 2>&1 >> ${backupFolder}/k8s_stats.txt || true
	$k get pod -A -o wide 2>&1 >> ${backupFolder}/k8s_stats.txt || true
	$k get svc -A 2>&1 >> ${backupFolder}/k8s_stats.txt || true
	$k get deploy -A -o wide 2>&1 >> ${backupFolder}/k8s_stats.txt || true
}

if [ "$gather" == 'controller' ];then
	envnamelabel="-${envname}-controller"
	if ! type $k >/dev/null 2>&1 ;then echo -e "[\e[1;31m✗\e[0m] ${bold}$k${nc} was not found. Exiting.."; exit 1;fi
	test -z "$envname" && envname=$($k get pod -A|grep -v '^default'|grep mysql|head -1|awk '{print $1}') && envnamelabel="-${envname}-controller"
	test -n "$envname" && echo -e "[i] Namespace: \e[1;31m${envname}\e[0m"

	# TODO: in cases where env is not found, we should still collect info on what went wrong
	if ! $k get ns|grep -q $envname ;then echo -e "[\e[1;31m✗\e[0m] Env $envname not found. Exiting..";exit 1;fi
	#mysql_pod="$($k -n $envname get pods --no-headers|grep mysql-|awk '{print $1}' | head -n 1)"

	get_disks
	get_k8s

	if [ "$extended" == '1' ];then
		echo "[i] backing up mysql databases.."
		#backup all mysql DBs:
		mysqldump_opts='--skip-comments'
		all_dbs="$($k -n $envname exec deploy/mysql -- mysql -AN $mysqldump_opts -e 'show databases' | grep -Ev "^(Database|performance_schema|information_schema|sys)$")"
		while read z;do
			if [ "$z" == "mysql" ];then
				$k -n $envname exec deploy/mysql -- mysqldump $mysqldump_opts --set-gtid-purged=OFF --databases $z --triggers --routines --events --add-drop-table --add-drop-database --single-transaction| sed '/.*DROP DATABASE IF EXISTS `mysql`/d' |gzip > ${backupFolder}/${thedate}_mysqldatabase_${z}_${envname}.sql.gz || true
			else
				$k -n $envname exec deploy/mysql -- mysqldump $mysqldump_opts --set-gtid-purged=OFF --databases $z --triggers --routines --events --add-drop-table --add-drop-database --single-transaction|gzip > ${backupFolder}/${thedate}_mysqldatabase_${z}_${envname}.sql.gz || true
			fi
		done <<< "$all_dbs"
	fi

	# get information_schema.innodb_trx
	$k -n $envname exec deploy/mysql -- mysql -e 'SHOW ENGINE INNODB STATUS\G' > ${backupFolder}/${thedate}_mysql_show_engine_innodb_status 2>/dev/null|| true
	$k -n $envname exec deploy/mysql -- mysql -e 'SELECT * FROM information_schema.innodb_trx\G' > ${backupFolder}/${thedate}_mysql_information_schema.innodb_trx 2>/dev/null|| true
	$k -n $envname exec deploy/mysql -- mysql -e 'SELECT * FROM performance_schema.data_locks' > ${backupFolder}/${thedate}_mysql_performance_schema.data_locks 2>/dev/null|| true
	$k -n $envname exec deploy/mysql -- mysql -e 'SELECT TABLE_SCHEMA,table_comment FROM INFORMATION_SCHEMA.TABLES WHERE table_name = "_database_version"' > ${backupFolder}/${thedate}_mysql_database_version 2>/dev/null|| true
	$k -n $envname exec deploy/mysql -- mysqldump --add-drop-table --no-data --single-transaction --skip-comments --triggers --routines --events metalsoft > ${backupFolder}/${thedate}_mysql_database_schema.sql 2>/dev/null|| true

	echo "[i] backing up couchdb.."
	#backup all couchdb DBs:
	couchdbUrl="$($k -n $envname get svc|grep couchdb|awk '{print $3,$5}'|sed 's/ /:/g'|cut -d/ -f1|cut -d: -f1,2)"
	test -n "$couchdbUrl" && curl -sk "http://${couchdbUrl}/_all_dbs" |jq -r ".[]"|while read z;do curl -sk "http://${couchdbUrl}/$z/_all_docs?include_docs=true"|jq '{"docs": [.rows[].doc]}' | jq 'del(.docs[]._rev)'|jq -c .|gzip > ${backupFolder}/${thedate}_couchdb_backup_${z}.gz;done || true

	echo "[i] backing up k8s pod runtime logs.."
	$k -n $envname get pod --no-headers|awk '{print $1}'|while read z;do $k -n $envname logs $z > ${backupFolder}/logs_pod_${z} 2>&1; $k -n $envname describe pod $z >  ${backupFolder}/describe_pod_${z} 2>&1;done
	$k -n $envname exec -it deploy/bsi -- bash -c 'supervisorctl status all' > ${backupFolder}/logs_pod_bsi_supervisorctl_status_all 2>&1
	mkdir -p ${backupFolder}/k8s_pod_bsi_varlog
	bsipod="$($k -n $envname get pod --no-headers|grep ^bsi|awk '{print $1}')"
	test -n "$bsipod" && while read bsi;do
	varlogs="$($k -n $envname exec -it $bsi -- bash -c 'find /var/log/ExportVHosts/bsi/BSI/Endpoints/JSONRPC/ -type f -iname "*.log"' 2>/dev/null|tr -d '\r')"
	test -n "$varlogs" && while read z;do $k -n $envname cp $bsi:${z} ${backupFolder}/k8s_pod_bsi_varlog/${bsi}_${z//\//_} &>/dev/null;done <<< "$varlogs"

	varlogsbsi="$($k -n $envname exec -it $bsi -- bash -c 'find /var/log/ -maxdepth 1 -type f -iname "bsi-*.log"' 2>/dev/null|tr -d '\r')"
	test -n "$varlogsbsi" && while read z;do $k -n $envname cp $bsi:${z} ${backupFolder}/k8s_pod_bsi_varlog/${bsi}_${z//\//_} &>/dev/null;done <<< "$varlogsbsi"
done <<< "$bsipod"

$k -n $envname get secret --no-headers|awk '{print $1}'|while read z;do echo -e '\n---';$k -n $envname get secret $z -o yaml;done > ${backupFolder}/k8s_secrets

if [ "$extended" == '1' ];then
	echo "[i] backing up k8s resources.."
	# k8s backups
	$k api-resources --no-headers|awk '{print $1}'|while read z;do mkdir -p ${backupFolder}/k8s_api_resources/${z};$k get $z --no-headers 2>/dev/null|awk '{print $1}'|while read a;do $k get $z $a -o yaml > ${backupFolder}/k8s_api_resources/${z}/${z}_${a}.yaml 2>/dev/null;done;done || true

	echo "[i] backing up k8s container logs.."
	test -d /var/log/containers && mkdir -p ${backupFolder}/container_logs && rsync -azL /var/log/containers/* ${backupFolder}/container_logs/ || true
fi

else # if gather=agent
	envname="$(grep -oP '\s+- URL=.*' /opt/metalsoft/agents/docker-compose.yaml|tail -1 |cut -d/ -f3)"
	envnamelabel="-${envname}-agent"
	echo "[i] backing up disk stats.."
	get_disks

	echo "[i] backing up docker stats.."
	test -f /opt/metalsoft/agents/docker-compose.yaml && mkdir -p ${backupFolder}/docker-agents && rsync -a /opt/metalsoft/agents/ ${backupFolder}/docker-agents/ || true
	test -d /opt/metalsoft/nfs-storage && ls -lahR /opt/metalsoft/nfs-storage/ > ${backupFolder}/nfs-storage_ls.txt || true
	systemctl status docker > ${backupFolder}/docker_status.txt || true
	docker ps -a > ${backupFolder}/docker_ps.txt || true
	docker ps|grep Restarting > ${backupFolder}/docker_restarting.txt || true
	docker ps|grep Restarting|awk '{print $1}'|while read z;do docker logs $z --tail=1000 > ${backupFolder}/docker_restarting_${z}.txt;done || true
	docker images -a > ${backupFolder}/docker_images.txt || true
	test -f /opt/metalsoft/agents/docker-compose.yaml && mkdir -p ${backupFolder}/docker-logs && grep -oP '\s+\-\s+\K/opt/metalsoft/logs[^\:]*' /opt/metalsoft/agents/docker-compose.yaml|while read z;do echo $z|while read f;do find $f -type f \( -iname "*.log" -o -iname "*.log.1" \) -exec cp {} ${backupFolder}/docker-logs/ \;;done;done


fi

echo "[i] creating an archive.."
resultFilename="${originalBackupFolder}/ms-diagnostics-${thedate}${envnamelabel}.tar.gz"
tar czf ${resultFilename} -C $(dirname ${backupFolder%*/}) ${backupFolder##*/} >/dev/null 2>&1 && \
	rm -rf $backupFolder && \
	filesize="$(ls -lh "${resultFilename}" | awk '{print  $5}')"
	echo -e "[\e[1;32m✓\e[0m][$filesize][${SECONDS}s] Please provide the following file to MetalSoft Team:\n${lightgreen}${resultFilename}${nc}" || { echo -e "[\e[1;31m✗\e[0m] Error: Unable to create: ${resultFilename}"; exit 2; }

	if [ "$pushfile" == "1" ];then
		echo -n "[i] Trying to auto-push the diagnostics file to MetalSoft [HTTPS]...${orange} " && curl -sk "https://diagnostics-report.metalsoft.io/?a=121&f=992&pushparam=1&ns=${envname}" -F diag=@"${resultFilename}" && echo -e "${nc}\n" || { echo -e "\n[\e[1;31m✗\e[0m] Failed pushing the diagnostics file to MetalSoft."; exit 1; }
	else
		if timeout 3 bash -c "</dev/tcp/176.223.248.10/443" 2>/dev/null; then
			curl -sk "https://diagnostics-report.metalsoft.io/?a=121&f=992&autopush=1&ns=${envname}" -F diag=@"${resultFilename}" &>/dev/null
		fi
		read -p "${orange}[?] Send the file to MetalSoft Team via HTTPS POST? [y/N]${nc} " yn
		case $yn in
			[Yy]* ) echo -n "[i] Trying to auto-push the diagnostics file to MetalSoft [HTTPS]...${orange} " && curl -sk "https://diagnostics-report.metalsoft.io/?a=121&f=992&promptedpush=1&ns=${envname}" -F diag=@"${resultFilename}" && echo -e "${nc}\n" || { echo -e "\n[\e[1;31m✗\e[0m] Failed pushing the diagnostics file to MetalSoft."; };;
			[Nn]* ) exit;;
			* ) exit;;
		esac
	fi
